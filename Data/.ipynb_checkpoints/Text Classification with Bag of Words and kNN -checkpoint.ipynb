{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary package\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function template function voc = buildVoc(folder, voc);\n",
    "#Inputs:\n",
    "#a folder is a folder path, which contains training data\n",
    "#b voc is a cell array to which the vocabulary is added so you can build a single lexicon for a set of\n",
    "#folders, the first time you call the fun voc is an empty cell array { }\n",
    "def buildVoc(folderpath,voc):\n",
    "    stopword = ['ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', \n",
    "    'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', \n",
    "    'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', \n",
    "    'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', \n",
    "    'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', \n",
    "    'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', \n",
    "    'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', \n",
    "    'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', \n",
    "    'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', \n",
    "    'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', \n",
    "    'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', \n",
    "    'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', \n",
    "    'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', \n",
    "    'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', \n",
    "    'further', 'was', 'here', 'than','']\n",
    "    for filename in os.listdir(folderpath):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            review=[]\n",
    "            filepath = folderpath + filename\n",
    "            f=open(filepath,'r')\n",
    "            review.append(f.read())\n",
    "            review[0] = re.sub(r'[^\\w\\s]','',review[0])\n",
    "            #lowercase all words\n",
    "            review[0]=review[0].lower()\n",
    "            split_review = review[0].split()\n",
    "            #get ride of stop words\n",
    "            stop_result=[]\n",
    "            for item in split_review:\n",
    "                if item not in stopword:\n",
    "                    stop_result.append(item)\n",
    "            removed_review = ' '.join(map(str,stop_result))\n",
    "            parse_review=removed_review.split()\n",
    "            c=Counter(parse_review)\n",
    "            result=[]\n",
    "            for i in c.items():\n",
    "                if i[1]>2:\n",
    "                    result.append(i[0])\n",
    "            voc.append(result)\n",
    "    return voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_voc=buildVoc('kNN/training/neg/',[])\n",
    "train_pos_voc=buildVoc('kNN/training/pos/',[])\n",
    "train_voc=train_neg_voc+train_pos_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lake',\n",
       " 'placid',\n",
       " 'predator',\n",
       " 'anaconda',\n",
       " 'kelly',\n",
       " 'crocodile',\n",
       " 'hector',\n",
       " 'movie',\n",
       " 'croc',\n",
       " 'like',\n",
       " 'doesnt',\n",
       " 'seem']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_voc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extrction(filepath,voc):\n",
    "    stopword = ['ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', \n",
    "    'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', \n",
    "    'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', \n",
    "    'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', \n",
    "    'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', \n",
    "    'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', \n",
    "    'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', \n",
    "    'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', \n",
    "    'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', \n",
    "    'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', \n",
    "    'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', \n",
    "    'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', \n",
    "    'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', \n",
    "    'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', \n",
    "    'further', 'was', 'here', 'than','']\n",
    "    feat_vec=[]\n",
    "    review=[]\n",
    "    f=open(filepath,'r')\n",
    "    review.append(f.read())\n",
    "    review[0] = re.sub(r'[^\\w\\s]','',review[0])\n",
    "    #lowercase all words\n",
    "    review[0]=review[0].lower()\n",
    "    split_review = review[0].split()\n",
    "    #get ride of stop words\n",
    "    stop_result=[]\n",
    "    for item in split_review:\n",
    "        if item not in stopword:\n",
    "            stop_result.append(item)\n",
    "    removed_review = ' '.join(map(str,stop_result))\n",
    "    parse_review=removed_review.split()\n",
    "    c=Counter(parse_review)\n",
    "    for i in c.items():\n",
    "        if i[1]>2:\n",
    "            feat_vec.append(i[1])\n",
    "    return feat_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 5, 3, 4, 3, 4, 3, 4, 3, 5, 4, 5]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extrction('kNN/training/neg/cv037_19798.txt',buildVoc('kNN/training/neg/',[])+buildVoc('kNN/training/pos/',[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
