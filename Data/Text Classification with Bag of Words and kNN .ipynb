{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary package\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stopword = ['ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', \n",
    "'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', \n",
    "'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', \n",
    "'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', \n",
    "'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', \n",
    "'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', \n",
    "'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', \n",
    "'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', \n",
    "'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', \n",
    "'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', \n",
    "'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', \n",
    "'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', \n",
    "'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', \n",
    "'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', \n",
    "'further', 'was', 'here', 'than','shes','']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function template function voc = buildVoc(folder, voc);\n",
    "#Inputs:\n",
    "#a folder is a folder path, which contains training data\n",
    "#b voc is a cell array to which the vocabulary is added so you can build a single lexicon for a set of\n",
    "#folders, the first time you call the fun voc is an empty cell array { }\n",
    "def buildVoc(folderpath,voc):\n",
    "\n",
    "    for filename in os.listdir(folderpath):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            review = []\n",
    "            filepath = folderpath + filename\n",
    "            f = open(filepath, 'r')\n",
    "            review.append(f.read())\n",
    "            review[0] = re.sub(r'[^\\w\\s]', '', review[0])\n",
    "            review[0] = re.sub(\"i'll|i've|didn't|you'|i'm|(it+s)|she's|`\", '', review[0])\n",
    "            #lowercase all words\n",
    "            review[0]=review[0].lower()\n",
    "            split_review = review[0].split()\n",
    "            #get ride of stop words\n",
    "            stop_result=[]\n",
    "            for item in split_review:\n",
    "                if item not in stopword and len(item) > 5:\n",
    "                    stop_result.append(item)\n",
    "            removed_review = ' '.join(map(str,stop_result))\n",
    "            parse_review=removed_review.split()\n",
    "            c = Counter(parse_review)\n",
    "            threshold = 3\n",
    "            # result=[]\n",
    "            for i in c.items():\n",
    "                if i[1] > threshold:\n",
    "                    voc.append(i[0])\n",
    "            # voc.append(result)\n",
    "    return voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_neg_voc=buildVoc('kNN/training/neg/', [])\n",
    "train_pos_voc=buildVoc('kNN/training/pos/', [])\n",
    "voc = train_neg_voc + train_pos_voc\n",
    "voc = list(filter(lambda x:voc.count(x) == 1, voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "metadata": {},
     "execution_count": 287
    }
   ],
   "source": [
    "len(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extrction(filepath, voc):\n",
    "    feature=[]\n",
    "    review=[]\n",
    "    f=open(filepath,'r')\n",
    "    review.append(f.read())\n",
    "    review[0] = re.sub(r'[^\\w\\s]', '', review[0])\n",
    "    review[0] = re.sub(\"i'll|i've|didn't|you'|i'm|(it+s)|she's|`\", '', review[0])\n",
    "    #lowercase all words\n",
    "    review[0]=review[0].lower()\n",
    "    split_review = review[0].split()\n",
    "    #get ride of stop words\n",
    "    stop_result=[]\n",
    "    for item in split_review:\n",
    "        if item not in stopword:\n",
    "            stop_result.append(item)\n",
    "    removed_review = ' '.join(map(str,stop_result))\n",
    "    parse_review=removed_review.split()\n",
    "    print(len(parse_review))\n",
    "    feat_vec = np.zeros(len(voc))\n",
    "    for item in parse_review:\n",
    "        if item in voc:\n",
    "            feat_vec[voc.index(item)] += 1\n",
    "\n",
    "    # c = Counter(parse_review)\n",
    "    # for i in c.items():\n",
    "    #     if i[1]>2:\n",
    "    #         feature.append(i[1])\n",
    "    \n",
    "    return feat_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "341\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 5., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 2., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 289
    }
   ],
   "source": [
    "feature_extrction('kNN/training/neg/cv000_29416.txt', voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "2d70ced986a378b9d35a242bc30e082338678f65c3eb24778ce5cfc708dec949"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}